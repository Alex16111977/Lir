"""
–í–ò–ü–†–ê–í–õ–ï–ù–ò–ô –ì–ï–ù–ï–†–ê–¢–û–† - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–Ü –≤–ø—Ä–∞–≤–∏ –∑ JSON
–ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—É—î —ñ—Å–Ω—É—é—á—ñ –≤–ø—Ä–∞–≤–∏!
–í–µ—Ä—Å—ñ—è: 1.0
"""

import json
import subprocess
import sys
from pathlib import Path
from typing import Dict, List

def check_existing_exercises():
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —è–∫—ñ JSON —Ñ–∞–π–ª–∏ –≤–∂–µ –º–∞—é—Ç—å –≤–ø—Ä–∞–≤–∏"""
    
    data_dir = Path(r'F:\AiKlientBank\Lir\data')
    categories = ['a2', 'b1', 'thematic']
    
    stats = {
        'total': 0,
        'with_exercise': 0,
        'without_exercise': 0,
        'files_without': []
    }
    
    print("[–ê–ù–ê–õ–Ü–ó] –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —ñ—Å–Ω—É—é—á–∏—Ö –≤–ø—Ä–∞–≤...")
    print("-" * 60)
    
    for category in categories:
        cat_dir = data_dir / category
        if not cat_dir.exists():
            continue
        
        for json_file in cat_dir.glob("*.json"):
            stats['total'] += 1
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'exercise' in data and data['exercise']:
                stats['with_exercise'] += 1
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —è–∫—ñ—Å—Ç—å –≤–ø—Ä–∞–≤–∏
                exercise = data['exercise']
                if exercise.get('text') and exercise.get('answers'):
                    print(f"  [OK] {json_file.name}: {len(exercise['answers'])} –ø—Ä–æ–ø—É—Å–∫—ñ–≤")
                else:
                    print(f"  [!] {json_file.name}: –Ω–µ–ø–æ–≤–Ω–∞ –≤–ø—Ä–∞–≤–∞")
            else:
                stats['without_exercise'] += 1
                stats['files_without'].append(f"{category}/{json_file.name}")
    
    print("\n[–°–¢–ê–¢–ò–°–¢–ò–ö–ê]")
    print(f"  –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤: {stats['total']}")
    print(f"  –ó –≤–ø—Ä–∞–≤–∞–º–∏: {stats['with_exercise']}")
    print(f"  –ë–µ–∑ –≤–ø—Ä–∞–≤: {stats['without_exercise']}")
    
    if stats['files_without']:
        print(f"\n[–£–í–ê–ì–ê] –§–∞–π–ª–∏ –ë–ï–ó –≤–ø—Ä–∞–≤:")
        for f in stats['files_without'][:10]:
            print(f"    - {f}")
    
    return stats

def add_missing_exercises_only():
    """–î–æ–¥–∞—î –≤–ø—Ä–∞–≤–∏ –¢–Ü–õ–¨–ö–ò –¥–æ —Ñ–∞–π–ª—ñ–≤, –¥–µ —ó—Ö –Ω–µ–º–∞—î"""
    
    data_dir = Path(r'F:\AiKlientBank\Lir\data')
    categories = ['a2', 'b1', 'thematic']
    
    added_count = 0
    
    print("\n[–î–û–î–ê–í–ê–ù–ù–Ø] –í–ø—Ä–∞–≤–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤ –ë–ï–ó –Ω–∏—Ö...")
    print("-" * 60)
    
    for category in categories:
        cat_dir = data_dir / category
        if not cat_dir.exists():
            continue
        
        for json_file in cat_dir.glob("*.json"):
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ù–ï —á—ñ–ø–∞—î–º–æ —Ñ–∞–π–ª–∏ –∑ —ñ—Å–Ω—É—é—á–∏–º–∏ –≤–ø—Ä–∞–≤–∞–º–∏!
            if 'exercise' in data and data['exercise']:
                continue
            
            # –î–æ–¥–∞—î–º–æ –≤–ø—Ä–∞–≤—É —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
            print(f"\n[NEW] {json_file.name}")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –≤–ø—Ä–∞–≤—É –∑ vocabulary
            vocabulary = data.get('vocabulary', [])
            if not vocabulary:
                print("  [SKIP] –ù–µ–º–∞—î vocabulary")
                continue
            
            # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 8 —Å–ª—ñ–≤ –¥–ª—è –≤–ø—Ä–∞–≤–∏
            exercise_words = {}
            for i, word_data in enumerate(vocabulary[:8]):
                german = word_data.get('german', '')
                translation = word_data.get('translation', '')
                if german and translation:
                    exercise_words[translation] = german
            
            if not exercise_words:
                print("  [SKIP] –ù–µ–º–∞—î —Å–ª—ñ–≤ –¥–ª—è –≤–ø—Ä–∞–≤–∏")
                continue
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ–∫—Å—Ç –≤–ø—Ä–∞–≤–∏ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            title = data.get('title', '–£—Ä–æ–∫')
            story = data.get('story', {})
            
            # –ù–∞–º–∞–≥–∞—î–º–æ—Å—è —Å—Ç–≤–æ—Ä–∏—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É –≤–ø—Ä–∞–≤—É
            exercise_text = create_contextual_exercise(story, vocabulary, exercise_words)
            
            data['exercise'] = {
                'title': f"–£–ü–†–ê–ñ–ù–ï–ù–ò–ï: {title.replace('üé≠', '').strip()}",
                'text': exercise_text,
                'answers': exercise_words
            }
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            added_count += 1
            print(f"  [OK] –î–æ–¥–∞–Ω–æ –≤–ø—Ä–∞–≤—É –∑ {len(exercise_words)} —Å–ª–æ–≤–∞–º–∏")
    
    return added_count

def create_contextual_exercise(story, vocabulary, exercise_words):
    """–°—Ç–≤–æ—Ä—é—î –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É –≤–ø—Ä–∞–≤—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å—Ç–æ—Ä—ñ—ó"""
    
    # –Ø–∫—â–æ —î —ñ—Å—Ç–æ—Ä—ñ—è, –Ω–∞–º–∞–≥–∞—î–º–æ—Å—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —ó—ó –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if story and story.get('content'):
        # –ë–µ—Ä–µ–º–æ –∫–ª—é—á–æ–≤—ñ —Ñ—Ä–∞–∑–∏ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó
        content = story['content']
        
        # –®—É–∫–∞—î–º–æ –∑–≥–∞–¥–∫–∏ —Å–ª—ñ–≤ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó
        sentences = []
        for rus_word, ger_word in list(exercise_words.items())[:8]:
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ä–µ—á–µ–Ω–Ω—è –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            if 'die' in ger_word or 'der' in ger_word or 'das' in ger_word:
                # –Ü–º–µ–Ω–Ω–∏–∫
                sentences.append(f"Wo ist ___ ({rus_word})?")
            elif 'en' in ger_word[-2:]:
                # –î—ñ—î—Å–ª–æ–≤–æ
                sentences.append(f"Er will ___ ({rus_word}).")
            else:
                # –ó–∞–≥–∞–ª—å–Ω–∏–π –≤–∏–ø–∞–¥–æ–∫
                sentences.append(f"Das ist ___ ({rus_word}).")
        
        return ' '.join(sentences)
    
    else:
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ —à–∞–±–ª–æ–Ω–∏ —è–∫—â–æ –Ω–µ–º–∞—î —ñ—Å—Ç–æ—Ä—ñ—ó
        templates = [
            "Hier ist ___ ({}).",
            "Er braucht ___ ({}).",
            "Sie hat ___ ({}).",
            "Wir sehen ___ ({}).",
            "Das war ___ ({}).",
            "Wo ist ___ ({})?",
            "Ich kenne ___ ({}).",
            "Du sagst: ___ ({})!"
        ]
        
        sentences = []
        for i, (rus_word, _) in enumerate(exercise_words.items()):
            if i < len(templates):
                sentences.append(templates[i].format(rus_word))
        
        return ' '.join(sentences)

def verify_and_regenerate():
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —Ç–∞ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä—É—î —Å–∞–π—Ç"""
    
    print("\n[–ì–ï–ù–ï–†–ê–¶–Ü–Ø] –ó–∞–ø—É—Å–∫ main.py...")
    print("-" * 60)
    
    result = subprocess.run(
        [sys.executable, r'F:\AiKlientBank\Lir\main.py'],
        capture_output=True,
        text=True,
        cwd=r'F:\AiKlientBank\Lir'
    )
    
    if result.returncode == 0:
        print("[OK] –°–∞–π—Ç –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ø—Ä–æ–±–ª–µ–º–Ω–∏–π —Ñ–∞–π–ª
        test_file = Path(r'F:\AiKlientBank\Lir\output\b1\gruppe_5_finale\14_Duel_bratev_B1.html')
        
        if test_file.exists():
            with open(test_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –ø—Ä–∞–≤–∏–ª—å–Ω–∞ –≤–ø—Ä–∞–≤–∞
            if 'die Ehre' in content and 'das Duell' in content:
                print("[OK] –í–ø—Ä–∞–≤–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î—Ç—å—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
            else:
                print("[ERROR] –í–ø—Ä–∞–≤–∞ –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î JSON!")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —â–æ –≤ HTML
                if '–£–ü–†–ê–ñ–ù–ï–ù–ò–ï' in content:
                    start = content.find('–£–ü–†–ê–ñ–ù–ï–ù–ò–ï')
                    end = content.find('</section>', start)
                    exercise_html = content[start:end][:500]
                    print("\n–í–ø—Ä–∞–≤–∞ –≤ HTML:")
                    print(exercise_html)
    else:
        print("[ERROR] –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó!")
        print(result.stderr)

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    
    print("=" * 70)
    print("–í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø –ì–ï–ù–ï–†–ê–¢–û–†–ê –í–ü–†–ê–í")
    print("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–Ü –≤–ø—Ä–∞–≤–∏ –∑ JSON!")
    print("=" * 70)
    
    # 1. –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–æ—Ç–æ—á–Ω–∏–π —Å—Ç–∞–Ω
    stats = check_existing_exercises()
    
    # 2. –î–æ–¥–∞—î–º–æ –≤–ø—Ä–∞–≤–∏ –¢–Ü–õ–¨–ö–ò –¥–µ —ó—Ö –Ω–µ–º–∞—î
    if stats['without_exercise'] > 0:
        print(f"\n[–ü–û–¢–†–Ü–ë–ù–û] –î–æ–¥–∞—Ç–∏ –≤–ø—Ä–∞–≤–∏ –¥–æ {stats['without_exercise']} —Ñ–∞–π–ª—ñ–≤")
        added = add_missing_exercises_only()
        print(f"\n[–†–ï–ó–£–õ–¨–¢–ê–¢] –î–æ–¥–∞–Ω–æ {added} –Ω–æ–≤–∏—Ö –≤–ø—Ä–∞–≤")
    else:
        print("\n[OK] –í—Å—ñ —Ñ–∞–π–ª–∏ –≤–∂–µ –º–∞—é—Ç—å –≤–ø—Ä–∞–≤–∏!")
    
    # 3. –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä—É—î–º–æ —Å–∞–π—Ç
    verify_and_regenerate()
    
    print("\n" + "=" * 70)
    print("[–ì–û–¢–û–í–û] –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–æ!")
    print("–¢–µ–ø–µ—Ä –≤–ø—Ä–∞–≤–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—é—Ç—å JSON —Ñ–∞–π–ª–∞–º")
    print("=" * 70)

if __name__ == "__main__":
    main()
